{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_hub in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow_hub) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow_hub) (4.25.6)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow_hub) (2.18.0)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tf-keras>=2.14.1->tensorflow_hub) (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (24.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\swapnil jain\\desktop\\audio_classification\\audio_classification\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow<2.19,>=2.18->tf-keras>=2.14.1->tensorflow_hub) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from vggish_input import waveform_to_examples\n",
    "from vggish import VGGish\n",
    "from vggish_params import Params\n",
    "from vggish_postprocess import Postprocessor\n",
    "\n",
    "# Load Google's VGGish model for feature extraction\n",
    "vggish = VGGish()\n",
    "params = Params()\n",
    "pproc = Postprocessor()\n",
    "\n",
    "# Function to extract features from a 5s audio clip\n",
    "def extract_features(audio_path):\n",
    "    y, sr = librosa.load(audio_path, sr=params.SAMPLE_RATE)\n",
    "    features = waveform_to_examples(y, sr)  # Convert waveform to VGGish input\n",
    "    return vggish(features)\n",
    "\n",
    "# Load dataset and preprocess\n",
    "def load_data(audio_folder, label_file):\n",
    "    audio_files = os.listdir(audio_folder)\n",
    "    labels = {}  # Map audio filenames to labels\n",
    "    \n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(',')\n",
    "            labels[parts[0]] = parts[1:]\n",
    "    \n",
    "    X, Y = [], []\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(labels.values())\n",
    "    \n",
    "    for file in audio_files:\n",
    "        path = os.path.join(audio_folder, file)\n",
    "        features = extract_features(path)\n",
    "        X.append(features)\n",
    "        Y.append(labels.get(file, []))\n",
    "    \n",
    "    Y = mlb.transform(Y)  # Convert labels to multi-hot encoding\n",
    "    return np.array(X), np.array(Y), mlb\n",
    "\n",
    "# Train Multi-Label Classification Model\n",
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=input_shape),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='sigmoid')  # Sigmoid for multi-label\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "audio_folder = 'C:\\Users\\SWAPNIL JAIN\\Desktop\\Audio_classification\\Audio_Classification\\artifacts\\data_preprocessing'\n",
    "label_file = 'path_to_labels.csv'\n",
    "X, Y, mlb = load_data(audio_folder, label_file)\n",
    "X = X.reshape(X.shape[0], -1)  # Flatten features\n",
    "model = build_model((X.shape[1],), len(mlb.classes_))\n",
    "model.fit(X, Y, epochs=20, batch_size=32, validation_split=0.2)\n",
    "model.save('poaching_detector.h5')\n",
    "\n",
    "# Inference Pipeline\n",
    "def predict_audio(audio_path, model, mlb):\n",
    "    y, sr = librosa.load(audio_path, sr=params.SAMPLE_RATE)\n",
    "    chunks = [y[i:i+5*sr] for i in range(0, len(y), 5*sr)]  # Split into 5s chunks\n",
    "    \n",
    "    results = []\n",
    "    for chunk in chunks:\n",
    "        features = waveform_to_examples(chunk, sr)\n",
    "        features = features.reshape(1, -1)  # Flatten for model input\n",
    "        pred = model.predict(features)\n",
    "        results.append(pred)\n",
    "    \n",
    "    avg_preds = np.mean(results, axis=0)\n",
    "    final_labels = [mlb.classes_[i] for i in range(len(avg_preds)) if avg_preds[i] > 0.5]\n",
    "    return final_labels\n",
    "\n",
    "# Example Usage\n",
    "predictions = predict_audio('test_audio.wav', model, mlb)\n",
    "print(\"Detected Classes:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
